---
title: 'Steps for installing a local AI copilot in Visual Studio Code'
description: "LLMs and AI coding assistants are all the rage. But what if you can't use tools like ChatGPT or GItHub Copilot at work? What if you have privacy concerns? For these situations, you can run LLMs locally on your computer."
image: '/blog/robot-computer.jpg'
pubDate: '2024-09-12'
---

Does your company block ChatGPT or GitHub Copilot? Do you have security or trust concerns sending your code to a third party AI service? You might not know this, but you can run a large language model (LLM) locally on your computer, and even integrate it with Visual Studio Code.

Using the [Ollama](https://ollama.com) tool, you can download and run models locally. In this post, I’ll guide you through the steps to run the Code Llama model using Ollama, and integrate it into Visual Studio Code.

[Code Llama](https://ollama.com/library/codellama) is an LLM from Meta that is focused on generating and talking about code. It’s based on their Llama 2 model, and supports many different languages.

## Installing Ollama and the Code Llama model

Your first step is to install Ollama. Go over to [https://ollama.com](https://ollama.com/download) where you can download and install it. Once Ollama is up and running, you should have a new terminal command, `ollama`. To see if it’s installed correctly, open a terminal and run:

```plaintext
ollama -v
```

This should print the Ollama version. If you see this, then you’re good to go! Next, download the Code Llama model by running this command:

```plaintext
ollama pull codellama
```

This may take a while, depending on your Internet connection. The 7b version of Code Llama is 3.8 gigabytes. Go get a cup of coffee, tea, or your favorite beverage while Ollama downloads this model.

## Setting up CodeGPT

[CodeGPT](https://codegpt.co/) has a Visual Studio Code extension where you can interact with models directly in the editor. In VS Code, go to the Extensions tab and search for “codegpt”. You’ll see several results, make sure to get the one with the blue check mark:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1726170993828/1be46d9e-84c7-4870-80c7-25913a59c425.png)

Once CodeGPT is installed, you should see a new CodeGPT icon in the editor’s sidebar. When you click on this, you’ll be taken to the CodeGPT interface. Click the dropdown menu at the top of this panel and select Ollama as the provider, and `codellama` as the model:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1726171147953/b1d32f3a-e024-4325-9daf-8d0aa160fc47.png)

Once you’re up and running, you will see a text area at the bottom of this panel to start chatting. Try entering a prompt such as “Generate the code for a simple React component”.

Code Llama will start processing your request. Keep in mind that running a model locally is not as powerful, or fast, as an online service like Meta AI or ChatGPT. After a few seconds, you should have a result in the chat window.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1726171287146/577825c9-e699-4df6-8fe4-c3f89e9504de.png)

## Setting up completion

You can also use CodeGPT to suggest code completion, like GitHub Copilot and similar tools do. To set this up, in the CodeGPT Chat window, click the Menu button at the top left part of the screen. A menu will slide out with several options.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1726171403849/787917d0-4413-4663-9e62-f8a585b56ad4.png)

Select “Autocomplete” to set up code completion.

Code Llama has a `code` variation that you can use for code completion. It is a separate model, so you’ll have to make another large download. Select the `codellama:code` model from the “AI Model” dropdown:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1726171506603/d179d376-0e4a-4bdc-9bde-0ebaa0dada60.png)

Next, make sure to click the toggle switch to enable completion:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1726171555493/75f284a1-b164-42b1-ade4-dc1f617319d5.png)

Now, as you type in your editor, Code Llama will make suggestions for you. For example, here it is filling in the `PropTypes` for a `Greeter` component:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1726171695622/757a28da-dc0d-4118-bdaf-b8c584ee3632.png)

If you like a suggestion, you can press the Tab key to accept it:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1726171724789/11fabb93-b01f-4eae-926d-1a9980729185.png)

## Have fun!

That’s really all there is to it. You now have AI chat and code completion integrated in Visual Studio Code!
